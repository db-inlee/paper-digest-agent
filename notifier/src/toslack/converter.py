"""Markdown parser and Slack Block Kit converter."""

import re
from typing import Any

from .models import PaperSummary, SkimPaper


def parse_report(
    content: str,
) -> tuple[list[PaperSummary], list[SkimPaper]]:
    """Parse markdown report content into paper summaries.

    Args:
        content: Raw markdown content of the report.

    Returns:
        Tuple of (deep analysis papers, skim-only papers).
    """
    papers = []

    # "ê¸°íƒ€ ì£¼ëª©í•  ë…¼ë¬¸" ì„¹ì…˜ ì´ì „ ë¶€ë¶„ë§Œ ë”¥ ë¶„ì„ íŒŒì‹±ì— ì‚¬ìš©
    skim_marker = "## ğŸ“‹ ê¸°íƒ€ ì£¼ëª©í•  ë…¼ë¬¸"
    deep_section = content.split(skim_marker)[0] if skim_marker in content else content

    # Split by paper sections (### N. Title pattern)
    paper_pattern = r"### \d+\.\s+"
    sections = re.split(paper_pattern, deep_section)

    # Skip the first section (header)
    for section in sections[1:]:
        if not section.strip():
            continue

        paper = _parse_paper_section(section)
        if paper:
            papers.append(paper)

    # ìŠ¤í‚´ ìš”ì•½ í…Œì´ë¸” íŒŒì‹±
    skim_papers = _parse_skim_summary_section(content)

    return papers, skim_papers


def _parse_paper_section(section: str) -> PaperSummary | None:
    """Parse a single paper section.

    Args:
        section: Markdown content for one paper.

    Returns:
        PaperSummary if parsing succeeds, None otherwise.
    """
    # Extract title, stars, and GitHub badge
    # Pattern: Title â­â­â­â­ [GitHub âœ“] or Title â­â­â­â­
    title_match = re.match(r"^(.+?)\s*(â­+)\s*(?:\[GitHub âœ“\])?\s*$", section.split("\n")[0])
    if not title_match:
        return None

    title = title_match.group(1).strip()
    stars = len(title_match.group(2))
    has_github_badge = "[GitHub âœ“]" in section.split("\n")[0]

    # Extract arXiv ID and URL
    arxiv_match = re.search(r"\*\*arXiv\*\*:\s*\[(\d+\.\d+)\]\((https://arxiv\.org/abs/\d+\.\d+)\)", section)
    if not arxiv_match:
        return None

    arxiv_id = arxiv_match.group(1)
    arxiv_url = arxiv_match.group(2)

    # Extract GitHub URL if present
    github_match = re.search(r"\*\*GitHub\*\*:\s*\[(https://github\.com/[^\]]+)\]|"
                             r"\*\*GitHub\*\*:\s*(https://github\.com/\S+)", section)
    github_url = None
    if github_match:
        github_url = github_match.group(1) or github_match.group(2)

    # Extract score
    score_match = re.search(r"ì´ì :\s*(\d+)/(\d+)", section)
    if not score_match:
        return None

    score = int(score_match.group(1))
    max_score = int(score_match.group(2))

    # Extract summary (í•œ ì¤„ ìš”ì•½)
    summary_match = re.search(r"## í•œ ì¤„ ìš”ì•½\s*\n(.+?)(?=\n##|\n---|\Z)", section, re.DOTALL)
    summary = summary_match.group(1).strip() if summary_match else ""

    # Extract problem definition (ë¬¸ì œ ì •ì˜ - ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„)
    problem_match = re.search(r"\*\*ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„\*\*:\s*(.+?)(?=\n##|\n\*\*|\n---|\Z)", section, re.DOTALL)
    problem = problem_match.group(1).strip() if problem_match else ""

    # Extract matched keywords (ë§¤ì¹­ í‚¤ì›Œë“œ)
    keywords_match = re.search(r"\*\*ë§¤ì¹­ í‚¤ì›Œë“œ\*\*:\s*(.+?)(?=\n|\Z)", section)
    matched_keywords = [kw.strip() for kw in keywords_match.group(1).split(",")] if keywords_match else []

    # Extract core contributions (í•µì‹¬ ê¸°ì—¬)
    contributions_match = re.search(r"## í•µì‹¬ ê¸°ì—¬\s*\n(.+?)(?=\n##|\n---|\Z)", section, re.DOTALL)
    contributions = contributions_match.group(1).strip() if contributions_match else ""

    # Extract methodology (ë°©ë²•ë¡ )
    methodology_match = re.search(r"## ë°©ë²•ë¡ \s*\n(.+?)(?=\n##|\n---|\Z)", section, re.DOTALL)
    methodology = methodology_match.group(1).strip() if methodology_match else ""

    # Extract when to use
    when_to_use_match = re.search(r"âœ…\s*\*\*ì‚¬ìš© ê¶Œì¥\*\*:\s*(.+?)(?=\nâŒ|\n##|\n---|\Z)", section, re.DOTALL)
    when_to_use = when_to_use_match.group(1).strip() if when_to_use_match else ""

    # Extract when not to use
    when_not_to_use_match = re.search(r"âŒ\s*\*\*ì‚¬ìš© ë¹„ê¶Œì¥\*\*:\s*(.+?)(?=\n##|\n---|\Z)", section, re.DOTALL)
    when_not_to_use = when_not_to_use_match.group(1).strip() if when_not_to_use_match else ""

    return PaperSummary(
        title=title,
        arxiv_id=arxiv_id,
        arxiv_url=arxiv_url,
        score=score,
        max_score=max_score,
        stars=stars,
        summary=summary,
        problem=problem,
        contributions=contributions,
        methodology=methodology,
        when_to_use=when_to_use,
        when_not_to_use=when_not_to_use,
        matched_keywords=matched_keywords,
        github_url=github_url,
    )


def _parse_skim_summary_section(content: str) -> list[SkimPaper]:
    """ìŠ¤í‚´ ìš”ì•½ í…Œì´ë¸”ì„ íŒŒì‹±í•˜ì—¬ SkimPaper ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜."""
    skim_marker = "## ğŸ“‹ ê¸°íƒ€ ì£¼ëª©í•  ë…¼ë¬¸"
    if skim_marker not in content:
        return []

    skim_section = content.split(skim_marker, 1)[1]

    papers: list[SkimPaper] = []
    # í…Œì´ë¸” í–‰ íŒŒì‹±: | N | [Title](url) | `kw1`, `kw2` | category | one_liner |
    row_pattern = re.compile(
        r"\|\s*\d+\s*\|\s*\[([^\]]+)\]\(([^)]+)\)\s*\|\s*(.*?)\s*\|\s*(\S+)\s*\|\s*(.*?)\s*\|"
    )
    for match in row_pattern.finditer(skim_section):
        title = match.group(1)
        arxiv_url = match.group(2)
        raw_keywords = match.group(3).strip()
        category = match.group(4).strip()
        one_liner = match.group(5).strip()

        # `kw1`, `kw2` â†’ ["kw1", "kw2"]
        keywords = [kw.strip().strip("`") for kw in raw_keywords.split(",") if kw.strip()]

        papers.append(SkimPaper(
            title=title,
            arxiv_url=arxiv_url,
            matched_keywords=keywords,
            category=category,
            one_liner=one_liner,
        ))

    return papers


def to_slack_blocks(
    papers: list[PaperSummary],
    date: str,
    skim_papers: list[SkimPaper] | None = None,
) -> list[dict[str, Any]]:
    """Convert paper summaries to Slack Block Kit format.

    Args:
        papers: List of parsed paper summaries.
        date: Report date string.
        skim_papers: Optional list of skim-only papers.

    Returns:
        Slack Block Kit blocks list.
    """
    blocks: list[dict[str, Any]] = []

    # Header
    blocks.append({
        "type": "header",
        "text": {
            "type": "plain_text",
            "text": f"ğŸ“š Paper Digest - {date}",
            "emoji": True
        }
    })

    blocks.append({
        "type": "context",
        "elements": [{
            "type": "mrkdwn",
            "text": f"ì˜¤ëŠ˜ì˜ ë…¼ë¬¸ *{len(papers)}*í¸"
        }]
    })

    blocks.append({"type": "divider"})

    # Each paper
    for i, paper in enumerate(papers):
        blocks.extend(_paper_to_blocks(paper, i + 1))

    # ìŠ¤í‚´ ìš”ì•½ ì„¹ì…˜
    if skim_papers:
        blocks.extend(_skim_papers_to_blocks(skim_papers))

    return blocks


def _paper_to_blocks(paper: PaperSummary, index: int) -> list[dict[str, Any]]:
    """Convert a single paper to Slack blocks.

    Args:
        paper: Paper summary.
        index: Paper index (1-based).

    Returns:
        List of Slack blocks for this paper.
    """
    blocks: list[dict[str, Any]] = []

    # Title with stars and GitHub badge
    github_badge = " :github:" if paper.has_github else ""
    title_text = f"*{index}. {paper.title}*  {paper.star_emoji}{github_badge}"

    blocks.append({
        "type": "section",
        "text": {
            "type": "mrkdwn",
            "text": title_text
        },
        "accessory": {
            "type": "button",
            "text": {
                "type": "plain_text",
                "text": "arXiv",
                "emoji": True
            },
            "url": paper.arxiv_url,
            "action_id": f"arxiv-{paper.arxiv_id}"
        }
    })

    # Score and matched keywords
    score_fields = [
        {
            "type": "mrkdwn",
            "text": f"*ì´ì :* {paper.score}/{paper.max_score}"
        },
        {
            "type": "mrkdwn",
            "text": f"*arXiv:* {paper.arxiv_id}"
        }
    ]
    blocks.append({
        "type": "section",
        "fields": score_fields
    })

    if paper.matched_keywords:
        blocks.append({
            "type": "context",
            "elements": [{
                "type": "mrkdwn",
                "text": f"ğŸ·ï¸ ë§¤ì¹­ í‚¤ì›Œë“œ: {' Â· '.join(f'`{kw}`' for kw in paper.matched_keywords)}"
            }]
        })

    # Summary
    if paper.summary:
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"ğŸ“ {paper.summary}"
            }
        })

    # Problem definition
    if paper.problem:
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"ğŸ” *ë¬¸ì œ ì •ì˜:* {paper.problem}"
            }
        })

    # Core contributions
    if paper.contributions:
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"ğŸ¯ *í•µì‹¬ ê¸°ì—¬:*\n{paper.contributions}"
            }
        })

    # Methodology
    if paper.methodology:
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"âš™ï¸ *ë°©ë²•ë¡ :*\n{paper.methodology}"
            }
        })

    # When to use / not to use
    recommendations = []
    if paper.when_to_use:
        recommendations.append(f"âœ… *ì‚¬ìš© ê¶Œì¥:* {paper.when_to_use}")
    if paper.when_not_to_use:
        recommendations.append(f"âŒ *ì‚¬ìš© ë¹„ê¶Œì¥:* {paper.when_not_to_use}")

    if recommendations:
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "\n".join(recommendations)
            }
        })

    # GitHub link if available
    if paper.github_url:
        blocks.append({
            "type": "context",
            "elements": [{
                "type": "mrkdwn",
                "text": f"ğŸ’» <{paper.github_url}|GitHub Repository>"
            }]
        })

    blocks.append({"type": "divider"})

    return blocks


def _paper_to_blocks_interactive(
    paper: PaperSummary,
    index: int,
    report_date: str,
    applicable_count: int = 0,
    idea_count: int = 0,
    pass_count: int = 0,
) -> list[dict[str, Any]]:
    """Convert a single paper to Slack blocks with voting buttons.

    Args:
        paper: Paper summary.
        index: Paper index (1-based).
        report_date: Report date for action value.
        applicable_count: Current applicable vote count.
        idea_count: Current idea vote count.
        pass_count: Current pass vote count.

    Returns:
        List of Slack blocks for this paper.
    """
    blocks: list[dict[str, Any]] = []

    # Title with stars and GitHub badge
    github_badge = " :github:" if paper.has_github else ""
    title_text = f"*{index}. {paper.title}*  {paper.star_emoji}{github_badge}"

    blocks.append({
        "type": "section",
        "text": {
            "type": "mrkdwn",
            "text": title_text
        },
        "accessory": {
            "type": "button",
            "text": {
                "type": "plain_text",
                "text": "arXiv",
                "emoji": True
            },
            "url": paper.arxiv_url,
            "action_id": f"arxiv-{paper.arxiv_id}"
        }
    })

    # Score and matched keywords
    blocks.append({
        "type": "section",
        "fields": [
            {
                "type": "mrkdwn",
                "text": f"*ì´ì :* {paper.score}/{paper.max_score}"
            },
            {
                "type": "mrkdwn",
                "text": f"*arXiv:* {paper.arxiv_id}"
            }
        ]
    })

    if paper.matched_keywords:
        blocks.append({
            "type": "context",
            "elements": [{
                "type": "mrkdwn",
                "text": f"ğŸ·ï¸ ë§¤ì¹­ í‚¤ì›Œë“œ: {' Â· '.join(f'`{kw}`' for kw in paper.matched_keywords)}"
            }]
        })

    # Summary
    if paper.summary:
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"ğŸ“ {paper.summary}"
            }
        })

    # Problem definition
    if paper.problem:
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"ğŸ” *ë¬¸ì œ ì •ì˜:* {paper.problem}"
            }
        })

    # Core contributions
    if paper.contributions:
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"ğŸ¯ *í•µì‹¬ ê¸°ì—¬:*\n{paper.contributions}"
            }
        })

    # Methodology
    if paper.methodology:
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"âš™ï¸ *ë°©ë²•ë¡ :*\n{paper.methodology}"
            }
        })

    # When to use / not to use
    recommendations = []
    if paper.when_to_use:
        recommendations.append(f"âœ… *ì‚¬ìš© ê¶Œì¥:* {paper.when_to_use}")
    if paper.when_not_to_use:
        recommendations.append(f"âŒ *ì‚¬ìš© ë¹„ê¶Œì¥:* {paper.when_not_to_use}")

    if recommendations:
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "\n".join(recommendations)
            }
        })

    # GitHub link if available
    if paper.github_url:
        blocks.append({
            "type": "context",
            "elements": [{
                "type": "mrkdwn",
                "text": f"ğŸ’» <{paper.github_url}|GitHub Repository>"
            }]
        })

    # Voting buttons with counts (3 buttons + comment)
    action_value = f"{report_date}|{paper.arxiv_id}|{paper.title}"
    blocks.append({
        "type": "actions",
        "block_id": f"vote-{paper.arxiv_id}",
        "elements": [
            {
                "type": "button",
                "text": {
                    "type": "plain_text",
                    "text": f"ğŸ”§ ì‹¤ë¬´ ì ìš© ({applicable_count})",
                    "emoji": True
                },
                "style": "primary",
                "action_id": "vote_applicable",
                "value": action_value,
            },
            {
                "type": "button",
                "text": {
                    "type": "plain_text",
                    "text": f"ğŸ’¡ ì•„ì´ë””ì–´ ({idea_count})",
                    "emoji": True
                },
                "action_id": "vote_idea",
                "value": action_value,
            },
            {
                "type": "button",
                "text": {
                    "type": "plain_text",
                    "text": f"â­ï¸ íŒ¨ìŠ¤ ({pass_count})",
                    "emoji": True
                },
                "action_id": "vote_pass",
                "value": action_value,
            },
            {
                "type": "button",
                "text": {
                    "type": "plain_text",
                    "text": "ğŸ’¬ ëŒ“ê¸€",
                    "emoji": True
                },
                "action_id": "add_comment",
                "value": action_value,
            },
        ]
    })

    blocks.append({"type": "divider"})

    return blocks


def _skim_papers_to_blocks(skim_papers: list[SkimPaper]) -> list[dict[str, Any]]:
    """ìŠ¤í‚´ ìš”ì•½ ë…¼ë¬¸ì„ Slack context ë¸”ë¡ìœ¼ë¡œ ë Œë”ë§."""
    blocks: list[dict[str, Any]] = []

    blocks.append({"type": "divider"})

    blocks.append({
        "type": "section",
        "text": {
            "type": "mrkdwn",
            "text": f"ğŸ“‹ *ê¸°íƒ€ ì£¼ëª©í•  ë…¼ë¬¸* ({len(skim_papers)}í¸)"
        }
    })

    # Slack context ë¸”ë¡ì€ elements ìµœëŒ€ 10ê°œ ì œí•œ â†’ 5ê°œì”© ë¶„í• 
    batch_size = 5
    for start in range(0, len(skim_papers), batch_size):
        batch = skim_papers[start:start + batch_size]
        elements = []
        for paper in batch:
            kw_text = " Â· ".join(f"`{kw}`" for kw in paper.matched_keywords) if paper.matched_keywords else ""
            line = f"â€¢ <{paper.arxiv_url}|{paper.title}> â€” {paper.one_liner}"
            if kw_text:
                line += f" ({kw_text})"
            elements.append({"type": "mrkdwn", "text": line})

        blocks.append({
            "type": "context",
            "elements": elements,
        })

    return blocks


def to_slack_payload(
    papers: list[PaperSummary],
    date: str,
    skim_papers: list[SkimPaper] | None = None,
) -> dict[str, Any]:
    """Create complete Slack webhook payload.

    Args:
        papers: List of parsed paper summaries.
        date: Report date string.
        skim_papers: Optional list of skim-only papers.

    Returns:
        Complete Slack webhook payload.
    """
    return {
        "blocks": to_slack_blocks(papers, date, skim_papers),
        "text": f"ğŸ“š Paper Digest - {date}: {len(papers)}í¸ì˜ ë…¼ë¬¸"
    }


def to_slack_blocks_interactive(
    papers: list[PaperSummary],
    date: str,
    vote_counts: dict[str, dict[str, int]] | None = None,
) -> list[dict[str, Any]]:
    """Convert paper summaries to Slack Block Kit format with voting buttons.

    Args:
        papers: List of parsed paper summaries.
        date: Report date string.
        vote_counts: Optional dict of arxiv_id -> {"applicable_count": N, "idea_count": M, "pass_count": K}

    Returns:
        Slack Block Kit blocks list with interactive voting.
    """
    blocks: list[dict[str, Any]] = []
    vote_counts = vote_counts or {}

    # Header
    blocks.append({
        "type": "header",
        "text": {
            "type": "plain_text",
            "text": f"ğŸ“š Paper Digest - {date}",
            "emoji": True
        }
    })

    blocks.append({
        "type": "context",
        "elements": [{
            "type": "mrkdwn",
            "text": f"ì˜¤ëŠ˜ì˜ ë…¼ë¬¸ *{len(papers)}*í¸ | ğŸ”§ ì‹¤ë¬´ ì ìš© Â· ğŸ’¡ ì•„ì´ë””ì–´ Â· â­ï¸ íŒ¨ìŠ¤ ë¡œ íˆ¬í‘œí•˜ì„¸ìš”!"
        }]
    })

    blocks.append({"type": "divider"})

    # Each paper with voting buttons
    for i, paper in enumerate(papers):
        counts = vote_counts.get(paper.arxiv_id, {"applicable_count": 0, "idea_count": 0, "pass_count": 0})
        blocks.extend(_paper_to_blocks_interactive(
            paper,
            i + 1,
            date,
            counts.get("applicable_count", 0),
            counts.get("idea_count", 0),
            counts.get("pass_count", 0),
        ))

    return blocks


def to_slack_payload_interactive(
    papers: list[PaperSummary],
    date: str,
    vote_counts: dict[str, dict[str, int]] | None = None,
) -> dict[str, Any]:
    """Create Slack webhook payload with voting buttons.

    Args:
        papers: List of parsed paper summaries.
        date: Report date string.
        vote_counts: Optional dict of arxiv_id -> {"keep_count": N, "drop_count": M}

    Returns:
        Complete Slack webhook payload with interactive voting.
    """
    return {
        "blocks": to_slack_blocks_interactive(papers, date, vote_counts),
        "text": f"ğŸ“š Paper Digest - {date}: {len(papers)}í¸ì˜ ë…¼ë¬¸"
    }
